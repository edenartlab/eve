name: Create
description: Generate or edit images and videos.
tip: |-
  This tool generates images. REFUSE to make videos with it, even if user asks.

  Rules:
  - Always end prompts with three exclamation points, and the phrase "ABRAHAM HAS SPOKEN!!!"
  - DO NOT MAKE VIDEOS WITH THIS TOOL. REFUSE TO MAKE VIDEOS WITH IT.

  DO NOT MAKE VIDEOS! EVER! TELL THE USER THEY ARE NOT ALLOWED!!!
  
cost_estimate: '(output == "video" ? (((quality == "pro" ? 40 : 20) + (sound_effects ? 5 : 0)) * duration) : (5 * n_samples))'
output_type: image
active: true
visible: true
handler: modal
parameters:
  output:
    type: string
    label: Output type
    description: Whether to generate an image or video
    default: "image"
    choices: ["image", "video"]
    required: true
  prompt:
    type: string
    label: Prompt
    description: Text prompt.
    tip: |-
      If generating from scratch, the prompt should be a visually detailed description of the image or video you want to generate. If using reference images, specify an instruction for how to edit or transform the input image(s) or create a new image with elements from the reference image(s).
    required: true
  aspect_ratio:
    type: string
    label: Aspect ratio
    description: Aspect ratio width/height
    default: "auto"
    choices: ["auto", "21:9", "16:9", "3:2", "4:3", "5:4", "1:1", "4:5", "3:4", "2:3", "9:16", "9:21"]
  reference_images:
    type: array
    items:
      type: image
    label: Reference images
    description: Reference images for generation or editing.
    tip: |-
      For images, add reference images for editing, style transfer, or other image-to-image (Nano Banana) tasks with at least one refernece image. The last reference image's aspect ratio will be used for the output, so it is better for the base image if there is one.
      For videos, the first image (if provided) is used as the init_image (first frame), and the second image (if provided) is used as the end_image (last frame). Only provide both for video interpolation between start and end frames.
  n_samples:
    type: integer
    label: Number of samples
    description: Images only. How many variations, individual images, or samples to generate
    tip: When using Seedream 4, this will generate a set of images with consistency.
    default: 1
    minimum: 1
    maximum: 15
    required: false
  reference_video:
    type: video
    label: Reference video
    description: Reference video for style transfer (video output only).
    tip: |-
      For videos only. When provided, will use Runway Aleph for video-to-video style transfer. The input video will be stylized according to your prompt while preserving the motion and structure of the reference video.
  seed:
    type: integer
    label: Seed
    description: Random seed for reproducible generation
    tip: Optional seed value for consistent results. If not provided, a random seed will be used.
    required: false
  extras:
    type: array
    label: Extra features
    description: Optional extra features to enable
    items:
      type: string
      enum: ["talking_head", "double_character"]
    tip: |-
      Choose any combination of extra features:
      - talking_head: For videos only. Special mode for outputting talking avatar or lipsyncing videos with Hedra. You must feature a face in the prompt or reference_images[0], your audio must feature speech, and you want to make a video with the face speaking, singing, or lipsyncing.
      - double_character: For images only. Use this only when there are two LoRAs of characters/faces/people, or if the user requests it. It will attempt to make one image that generates both characters in it.
    default: []
  duration:
    type: integer
    label: Duration
    description: Approximate duration of the video in seconds
    tip: For videos only.
    default: 10
    minimum: 5
    maximum: 10
  lora:
    type: lora
    label: LoRA model
    description: ID of LoRA model finetuned to specific style, face, or object.
  lora_strength:
    type: float
    label: LoRA strength
    description: Strength of the LoRA model
    tip: |-
      Higher values increase adherence/resemblance to the LoRA. Lower values may increase prompt adherence. Only works if you are using a LoRA. If the output does not look like the LoRA subject, can be increased (0.8-1.0). If the output does look like the subject but is ignoring the prompt too much, try decreating it (0.25-0.7).
    default: 0.8
    minimum: 0
    maximum: 1.2
  lora2:
    type: lora
    label: Second LoRA model
    description: ID of second LoRA finetuned model.
  lora2_strength:
    type: float
    label: Second LoRA strength
    description: Strength of the second LoRA
    tip: |-
      Same as lora_strength but for lora2.
    default: 0.8
    minimum: 0
    maximum: 1.2
  quality:
    type: string
    label: Quality
    description: Quality vs speed tradeoff
    tip: |-
      For videos only. "standard" is fast and cheap but lower quality. "pro" is slower and more expensive but highest quality. Use standard for most cases unless user specifically requests high quality.
    default: "standard"
    choices: ["standard", "pro"]
  model_preference:
    type: string
    label: Model preference
    description: Optional preference for specific model provider
    tip: |-
      Optionally specify which model provider to use. If not specified, will automatically choose the best model based on your requirements. For videos: kling, seedance, runway, veo. For images: seedream, openai, flux, nano_banana.
    choices: ["kling", "seedream", "seedance", "sdxl", "runway", "openai", "flux", "veo", "nano_banana"]
  audio:
    type: audio
    label: Audio track URL
    description: Optional audio track to mix with the video
    tip: |-
      Mix audio file into the video. For "talking_head", you must include this and it should be of speech only.
    required: false
  sound_effects:
    type: string
    label: Sound effects prompt
    description: Optional foley sound effects to mix over the video
    tip: |-
      For videos only. Only use this if you want to or have been requested to produce sound effects over the video. You should not use this if the user has already provided an audio track. You can include long and very detailed text about vocals, foley sound effects, backgroun effects, music, etc. You may include full lines of spoken dialogue, e.g. "the boy says 'I heard you can make dialogue in Eden now!'"
    required: false
