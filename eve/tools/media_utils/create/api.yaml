name: Create
description: Generate or edit images and videos from an objective, single-scene prompt plus optional reference media.
tip: |-
  Images:
    - For multi-image consistency sets, prefer model_preference=seedream and set n_samples accordingly.
    - For text-heavy designs (infographics, logos, signage), prefer model_preference=seedream (or openai / nano_banana).
  
  Videos:
    - If reference_images or reference_video are provided, describe only motion/camera/dynamics in the prompt and refer to the specific references; do not re-prompt static content already provided by references.
    - Use sound_effects if you need synthesized dialogue/foley/music. Do not mix a separate audio file unless using extras.talking_head.

  Aspect ratio:
    - Use 16:9 (landscape), 1:1 (square), 9:16 (portrait) unless the user specifies otherwise.
    - If aspect_ratio != "auto", it overrides any aspect ratio inferred from references.
cost_estimate: '(output == "video" ? (((quality == "pro" ? 40 : 20) + (sound_effects ? 5 : 0)) * duration) : (5 * n_samples))'
output_type: image
active: true
visible: true
handler: modal
parameters:
  output:
    type: string
    label: Output type
    description: Whether to generate an image or video
    default: "image"
    choices: ["image", "video"]
    required: true
  prompt:
    type: string
    label: Prompt
    description: One objective, single-scene instruction for what to generate or edit. No roleplay.
    tip: |-
      Write a concise, structured brief the model can execute deterministically.

      From-scratch (image or video):
        • Purpose (asset/use) → Subject + Action → Environment/Context → Style/Lighting/Camera → Composition/Framing.
        • Use full sentences, not keyword lists. Put any literal text to render in "double quotes".
        • Do not mention tool parameters in the prompt (aspect ratio, model, etc. go in their fields).

      Edits (image or video):
        • Use: Action + Target + Location + Keep/Constraints.
        • Refer to references by index/role: “Image 1 …”, “Image 2 …”. (Image 1 = reference_images[0])
        • Be explicit about what stays unchanged (e.g., “keep pose and background”).
        • Be surgical: specify exactly what to change and what must remain unchanged.
        • Avoid pronouns; reference the object directly (“the woman’s jacket”, not “her jacket”).
      
      Reference usage:
        • Combine by role: “Use the composition from Image 1, the character from Image 2, and the ink style from Image 3.”
        • For identity/style transfer, specify what to extract (“maintain character identity from Image 2”) and where to apply it.
        • If multiple references are provided, name each and state its function to avoid ambiguity.
      
      Video-specific:
        • If init/end images or a reference video are provided, describe only motion/camera/dynamics, timing, and transitions.
        • Include camera moves (“slow dolly-in”, “handheld sway”), pacing (“2‑second hold”, “quick cut”), and action beats.
        • Put dialogue/foley/music in the sound_effects parameter, not in the prompt.

      Phrasing:
        • Prefer positive constraints (“empty street”) over negatives (“no cars”).
        • Use precise placements (“logo on left chest”, “3/4 view ~30°”, “shoulder‑up crop”).
      
      Mini-examples:
        • From-scratch: “Poster: A red sports coupe drifting on a wet city street at night, neon reflections, photoreal 50mm, low angle, golden rim light, dramatic rain streaks, centered composition.”
        • Edit w/ refs: “Image 1: replace the background with a sunset cityscape in watercolor style from Image 3; keep the subject from Image 1 and maintain her outfit; add title text at top reading 'Summer Festival'.”
    required: true
  aspect_ratio:
    type: string
    label: Aspect ratio
    description: Output aspect ratio (width:height).
    tip: If not "auto", this overrides any ratio inferred from references.
    default: "auto"
    choices: ["auto", "21:9", "16:9", "3:2", "4:3", "5:4", "1:1", "4:5", "3:4", "2:3", "9:16", "9:21"]
  reference_images:
    type: array
    items:
      type: image
    label: Reference images
    description: Reference images for generation or editing.
    tip: |-
      Use for editing, identity/style transfer, composition borrowing, or other image-to-image tasks.
      - Label references in the prompt as Image 1, Image 2, … (Image 1 = reference_images[0]).
      - When multiple references are used, state each image’s role (e.g., Image 1: base subject; Image 2: outfit; Image 3: art style).
      - For video interpolation: reference_images[0] = init frame, reference_images[1] = end frame.
      - If aspect_ratio is set to auto, it will follow the last reference image’s aspect ratio; set aspect_ratio explicitly to control it.
  n_samples:
    type: integer
    label: Number of samples
    description: Images only. How many variations, individual images, or samples to generate
    tip: Generates multiple images. With model_preference=seedream, n_samples can be used for consistent sets (same identity/style across images).
    default: 1
    minimum: 1
    maximum: 15
    required: false
  reference_video:
    type: video
    label: Reference video
    description: Reference video for style transfer (video output only).
    tip: |-
      For videos only. When provided, will use Runway Aleph for video-to-video style transfer, regardless of model_preference. The input video will be stylized according to your prompt while preserving the motion and structure of the reference video.
  seed:
    type: integer
    label: Seed
    description: Random seed for reproducible generation
    tip: Optional seed value for consistent results. If not provided, a random seed will be used.
    required: false
  extras:
    type: array
    label: Extra features
    description: Optional extra features to enable
    items:
      type: string
      enum: ["talking_head", "double_character"]
    tip: |-
      - talking_head (videos only): For lip-sync or talking avatars (Hedra). Requires a face in references or prompt and a speech-only audio file in the audio parameter.
      - double_character (images only): Use only when generating two distinct character LoRAs/faces in one image.
    default: []
  duration:
    type: integer
    label: Duration
    description: Approximate duration of the video in seconds
    tip: For videos only.
    default: 10
    minimum: 5
    maximum: 10
  lora:
    type: lora
    label: LoRA model
    description: ID of LoRA model finetuned to specific style, face, or object.
  lora_strength:
    type: float
    label: LoRA strength
    description: Strength of the LoRA model
    tip: |-
      Higher values increase resemblance to the LoRA subject; lower values increase prompt adherence. 
      Typical ranges: 0.25–0.7 (balanced), 0.8–1.0 (strong likeness). If likeness is weak, increase. If likeness is too strong and ignores prompt, decrease.
    default: 0.8
    minimum: 0
    maximum: 1.2
  lora2:
    type: lora
    label: Second LoRA model
    description: ID of second LoRA finetuned model.
  lora2_strength:
    type: float
    label: Second LoRA strength
    description: Strength of the second LoRA
    tip: |-
      Same as lora_strength but for lora2.
    default: 0.8
    minimum: 0
    maximum: 1.2
  quality:
    type: string
    label: Quality
    description: Quality vs speed tradeoff
    tip: |-
      For videos only. "standard" is fast and cheap but lower quality. "pro" is slower and more expensive but highest quality. Use standard for most cases unless user specifically requests high quality.
    default: "standard"
    choices: ["standard", "pro"]
  model_preference:
    type: string
    label: Model preference
    description: Optional preference for specific model provider
    tip: |-
      Optionally choose a provider. If omitted, the system auto-selects based on task.
      Videos: kling, seedance, runway, veo. Images: seedream, openai, flux, nano_banana.
    choices: ["kling", "seedream", "seedance", "sdxl", "runway", "openai", "flux", "veo", "nano_banana"]
  audio:
    type: audio
    label: Audio track
    description: Speech audio file (videos + extras.talking_head only).
    tip: |-
      Only valid when extras includes "talking_head". Provide a speech-only track to drive lip-sync. 
      For generic background music or SFX mixing, use the media_editor tool instead.
    required: false
  sound_effects:
    type: string
    label: Sound effects / dialogue
    description: Optional synthesized dialogue, foley, or music to generate over the video.
    tip: |-
      Videos only. Use when you want the system to synthesize audio (dialogue in quotes, foley, ambience, music).
      If an audio track is provided for talking_head, sound_effects are ignored.
    required: false
